% Thank Dima especially
% Dataset providers
% Thank Lorenz Kruger, Martin and others in group (Lukas Weigand).
\dots

This research was supported in part through the Maxwell computational resources operated at \gls{DESY}, Hamburg, Germany

The \texttt{Python} data science and visualization ecosystem was heavily employed in this thesis.
The usage of \texttt{Xarray} \cite{hoyerXarrayNDLabeled2017} for multidimensional dataset transformations, \texttt{matplotlib} \cite{hunterMatplotlib2DGraphics2007} for plotting of images and other figures, \texttt{pandas} \cite{thepandasdevelopmentteamPandasdevPandasPandas2024} for tabular assessment of data, \texttt{seaborn} \cite{waskomSeabornStatisticalData2021} for statistical plotting, \texttt{optuna} \cite{akibaOptunaNextgenerationHyperparameter2019} for hyperparameter optimization, are acknowledged by citation as this is preferred by these scientific libraries. 

Extensive use of the \texttt{SED} (\href{https://github.com/OpenCOMPES/sed}{https://github.com/OpenCOMPES/sed}) is made, especially allowing easy manipulation of the single-event dataframes with $>$\num{1e9} rows, extremely fast binning to multidimensional images and compatibility with \gls{HDF5} and tiff formats.

For deep learning, exclusively \texttt{PyTorch} \cite{paszkePyTorchImperativeStyle2019} has been used. We use the \texttt{UNET3D} shown in \cite{cicek3DUNetLearning2016}, implemented (modified to accommodate our needs) by \citeauthor{wolnyAccurateVersatile3D2020} \cite{wolnyAccurateVersatile3D2020}. \texttt{PyTorch} \texttt{Dataset} and \texttt{DataLoader} classes were extensively used to ease in experiments other than deep learning.


\dots

Many of the concepts about Statistical Learning Theory were introduced to the author by the lecture series \texttt{Algorithmic Foundations of Data Science} taught by Prof. Martin Grohe at the RWTH Aachen University.
