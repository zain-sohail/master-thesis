The goal of image restoration, detached from a specific noise model, is to estimate the latent\footnote{\textit{Latent} variables are unobserved and can only be inferred from the observed data.} clean image $Y \in \mathbb{R}^{n_1 \times n_2 \times \cdots \times n_d}$\todo[disable]{It's always good to state where objects come from, i.e., in which spaces they are. Here it could be $Y\in\mathbb{R}^{n_1\times\cdot\times n_d}$ if $Y$ is a $d$-dimensional discrete real valued image.}, a $d$-dimensional discrete real-valued image, from an incomplete or corrupted (noisy) image  $X \in \mathbb{R}^{n_1 \times n_2 \times \cdots \times n_d}$\todo[disable]{$\in$?}. The voxel values of noisy $X$ and latent clean $Y$ images can be written as $x_{\mathbf{i}}$ and $y_{\mathbf{i}}$\todo[disable]{This kinds of reverses the logic. Before you can connect the observation $X$ to the true image $Y$, you first need to define exactly what the true image $X$ is supposed to be. From the above I would say it's a d-array of real values.}, respectively, where $\mathbf{i} \in \mathcal{I}$\todo[disable]{$\in$? In any case, the set of all possible indices should have a name, e.g., $\mathcal{I}$.}, and

\begin{equation*}
    \mathcal{I} = \{[i_1, i_2, \dots, i_d]^T \mid i_1 \in [1, n_1], i_2 \in [1, n_2], \dots, i_d \in [1, n_d]\}
\end{equation*}
is the index set in the $d$-dimensional space.

\todo[disable]{From where to where does $\mathcal{F}$ map? Also, this does not seem very general, since this $\mathcal{F}$ is limited to operate pixel-wise and cannot take into account the position $\mathbf{i}$ at all. It still may be general enough for what you need though. I don't know yet, since I just started reading.}
In the most general form, the observation model can be defined as $X$ being a mapping of $Y$ through a function $\mathcal{F}$, which is generally stochastic. This can be written as:\todo[disable]{Will you give examples for $\mathcal{F}$ later? I think it would already be a good place to have a very simple example right here, e.g. additive noise. Then we probably see, that this is not truly a function, but involves a random variable.}
\begin{equation}\label{eq:observation-model}
    X = \mathcal{F} (Y)
\end{equation}
where $\mathcal{F}$ can vary depending on the noise model (e.g., additive or multiplicative noise, etc.), or other corruptions such as blurring, distortions etc. \todo[disable]{To understand that, you should put an example $\mathcal{F}$ here. I'm not completely sure how you mean this exactly.}

One widely used model is additive noise model, where the function $\mathcal{F}(Y)$ simply adds noise $N$ to the clean image $Y$. In this case, the observation model can be written as:
\begin{equation}\label{eq:observation-model-additive}
    X = Y + N
\end{equation}
\todo[disable]{This does not fit into your framework for the mapping $\mathcal{F}$, because this does not do the same at every pixel: At pixel $\mathbf{i}$, the noise $n_\mathbf{i}$ is added, but this depends on $\mathbf{i}$.}

where the common assumption for $N$ is \gls{AWGN}, normal distributed $\mathcal{N}$ with mean \num{0} and variance $\sigma^2$
\begin{equation}\label{eq:awgn}
    N \sim \mathcal{N}(0, \sigma^2)
\end{equation}
\todo[disable]{This equation seems to be incomplete, $\mathcal{N}(0, \sigma^2)$ (make sure you have defined this notation) is a scalar valued distribution, but the way you use $N$, it must be a matrix, where every entry of that matrix is drawn independently from $\mathcal{N}(0, \sigma^2)$.}

The inverse problem, of image restoration\footnote{Depending on context, also referred to as reconstruction or denoising}, to estimate $Y$ from $X$, is an \textit{ill-posed} problem; meaning that there are multiple possible solutions of the estimated image $\hat{Y}$ that are not unique or equal to the true image $Y$. This is due to the loss of information during the observation process, leading to an under-determined system. Depending on the prior knowledge posed, different estimates of the latent clean image can be recovered.

In the following chapter, we shall look at an \gls{AWGN} denoising algorithm--the celebrated \gls{BM3D}, introduced first by \citeauthor{dabovImageDenoisingSparse2007} in \cite{dabovImageDenoisingSparse2007}, building upon many of the classical denoising techniques such as transform domain denoising, \gls{NLM} and filtering methods (such as the Wiener filter). We will look at its application to \gls{MPES} data, by first defining a noise model for the data, discussing the Anscombe \gls{VST}, finding optimal denoising level for different noise levels ($\propto$ \gls{ncounts}) and evaluating its performance using the \gls{MSSSIM}.

\section{Image Denoising in Spatial and Transform Domains}
Image restoration techniques have been explored in both the spatial and transform domains\todo[disable]{Directly give an example for what transform domains are, e.g., the frequency domain.} \cite{buadesReviewImageDenoising2005,diwakarReviewCTImage2018}. For instance, the Fourier transform is commonly used to map images to the frequency domain. A simple way of denoising in this transform domain is to filter out the high frequency components that typically represent noise elements, followed by an inverse Fourier transform. Other transforms include wavelet transforms, discrete cosine transforms, and curvelet transforms.

In the spatial domain, several linear and nonlinear filtering techniques exist, utilizing different kernels to perform direct manipulation on pixel values. Linear filters, such as the mean filter, compute the\todo[disable]{inserted ``weighted''} weighted average of pixel values in a neighborhood and, in doing so, smooth the image but usually result in edge blurring. Another popular linear filter is the Gaussian filter, which applies a Gaussian kernel to the image to perform smoothing.
\todo[disable]{This short literature overview needs references that back your statements.}

\subsection{Wiener Filter}
\todo[disable]{Would be nice to have more details on the Wiener filter here. This is used in BM3D, so it's highly relevant.}
Wiener filtering is a transform domain restoration technique operating on statistical principles. Based on the additive noise model defined in \cref{eq:observation-model-additive}, it aims to minimize the \gls{MSE} between the estimated $\hat{Y}$ and latent clean image $Y$, which can be written as:

\begin{equation}\label{eq:wiener-mse}
    \hat{Y} = \arg \min_{\hat{Y}} \mathbb{E} \left[ \| Y - \hat{Y} \|^2 \right]
\end{equation}

This formulation is a case of risk minimization, a concept discussed in \cref{ch:deep_learning} in the context of learning algorithms. The noisy signal $X$ can be expressed in the frequency domain (Fourier basis) using the Fourier transform $\mathfrak{F}$ as:

\begin{equation*}
    X(f) = \mathfrak{F}(X)
\end{equation*}

where $f$ is the frequency. The Wiener filter is then expressed as a linear filter that scales each frequency component of the observed signal based on the \glspl{PSD} of $Y$ and $N$: 

\begin{equation*}
H(f) = \frac{S_Y(f)}{S_Y(f) + S_N(f)}
\end{equation*}

with $S_Y(f)$ and $S_N(f)$ the \gls{PSD} of latent image $Y$ and noise $N$, respectively. The most common Wiener filtering technique assumes the \gls{PSD} of $N$ is assumed constant, which is the case of \gls{AWGN}. However, usage of other additive noise priors is as easy as changing the \gls{PSD} of $N$.

For an optimal filter $H(f)$, based on image properties, it can be applied to the observed signal $X(f)$ to estimate the latent clean image in the frequency domain:

\begin{equation*}
    \hat{Y}(f) = H(f) X(f)
\end{equation*}

and this can be transformed back to the spatial domain to obtain a denoised estimate

\begin{equation*}
    \hat{Y} = \mathfrak{F}^{-1}(\hat{Y}(f))
\end{equation*}

Notice from above that the Wiener filter requires access to the latent clean image $Y$ to compute $S_Y(f)$, which is generally not available. Hence, empirical Wiener filters\footnote{This then becomes a case of empirical risk minimization.}, based on noisy $X$, were proposed by \citeauthor{yaroslavskyDigitalPictureProcessing1985} \cite{yaroslavskyDigitalPictureProcessing1985}. The method follows a moving window approach, where the filtering is estimated from the local statistics of the image. The filter is then applied to the central pixel of the window and inverted to estimate the latent clean image.

As the Fourier basis operates globally, applying Wiener filtering with this basis can introduce periodic artifacts, as global transforms may overemphasize large-scale image features and fail to capture fine local details. This limitation has motivated the development of local adaptive variants and the exploration of alternative transform domains such as wavelets, which better capture local image characteristics \cite{buadesReviewImageDenoising2005}.

\subsection{Non-Local Means}
\todo[inline]{Since NLM is quite related to BM3D, it would also be helpful to define this in detail here. The definition is not that involved and I would say quite instructive to understand the non-locality.}
\todo[disable]{``also''? What else uses this redundancy? BM3D, but you haven't mentioned that one yet. At leae not in this chapter.}

Other than linear filters, non-linear filters such as the median filter, replace each pixel with the median value of its neighbors and are much better at removing salt-and-pepper noise. Other approaches, such as bilateral filtering, combine spatial proximity and intensity similarity, allowing for selective smoothing that  preserves sharpness around edges. 

The principle behind \gls{NLM} denoising builds on the redundancy of similar patches in the image and estimates a pixel value by taking a weighted average over other pixels with a similar local structure, regardless of their spatial distance. By utilizing these priors, denoising algorithms can indeed aggressively use the intrinsic properties of the images and thereby enhance the visual quality and provide estimates closer to the latent clean image.

Non-Local Means (NLM) denoising is a highly effective method for removing noise by leveraging the inherent redundancy found in natural images. Unlike local filters, which operate on immediate pixel neighborhoods, NLM uses a non-local approach, meaning that it searches the entire image for patches or neighborhoods that resemble the local structure of a pixel's neighborhood, regardless of their spatial distance. The algorithm replaces a noisy pixel by computing a weighted average of all pixels in the image, with the weights determined by the similarity of their neighborhoods.

The similarity between the neighborhoods of pixels $i$ and $j$ is measured using the Gaussian-weighted Euclidean distance between intensity vectors in a window surrounding each pixel:

\begin{equation}
    w(i,j) = \frac{1}{Z(i)} \exp \left( -\frac{\|v(\mathcal{N}_i) - v(\mathcal{N}_j)\|_{2,a}^2}{h^2} \right),
\end{equation}

where $v(\mathcal{N}_i)$ is the vector of pixel intensities within the neighborhood $\mathcal{N}_i$ of pixel $i$, and $h$ is a parameter controlling the decay of weights as a function of this distance. The normalization factor $Z(i)$ ensures that the weights sum to 1 for each pixel $i$.

NLM is particularly effective at preserving edges and textures in the image, as the weight $w(i,j)$ assigns higher values to pixels whose neighborhoods are similar in appearance to the target pixel's neighborhood. As a result, NLM performs well in removing noise while maintaining important image features, making it a popular choice for denoising tasks, especially when the noise is uniformly distributed across the image.


\section{BM3D: Denoising in Sparse Domain}

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{images/bm3d_schematic.png}
    \caption{Block diagram showing the 2-stage \gls{BM3D} algorithm, consisting of block matching, collaborative filtering, and aggregation. Reprinted from \cite{wangFPGABasedHardwareAccelerator2020}, under the terms of the Creative Commons Attribution 4.0 International License.}
    \label{fig:bm3d-schematic}
\end{figure}


As shown in \cref{alg:bm3d} and \cref{fig:bm3d-schematic}
\todo[inline]{This needs more details. Try to provide the essential formulas of what is actually computed for all steps. You don't need to put those details into the algorithm, it's better to add them to the main text.}
, the \gls{BM3D} scheme works by grouping similar patches in a 2D image and applying a 3D transform\footnote{This algorithm has also been proposed for 3D images, dubbed BM4D \cite{mNonlocalTransformdomainFilter}.}. This leads to an enhanced sparse representation of the image which after filtering is transformed back to the spatial domain.
% Main BM3D Algorithm
\begin{algorithm}
    \caption{BM3D Denoising Algorithm}\label{alg:bm3d}
    \begin{algorithmic}[1]
    \Require Noisy image $X$, noise variance $\sigma^2$
    \Ensure Denoised image $\hat{Y}$
    \Statex
    \Procedure{BM3D}{$X$, $\sigma^2$}
        \State $\hat{Y} \gets X$
        
        \For{each reference block $B_R$ in $X$}
            \State $B_{G} \gets \textsc{BlockMatching}(B_R, X)$
            \State $B_{F} \gets \textsc{CollaborativeFiltering}(B_{G}, \sigma^2)$
            \State \textsc{Aggregate} $B_{F}$ into $\hat{Y}$
        \EndFor
        
        \State \textbf{return} $\hat{Y}$
    \EndProcedure
    \end{algorithmic}
\end{algorithm}

In the Grouping step, candidate blocks $B_i$ which are the least dissimilar to an $N_1 \times N_1$ reference block $B_R$ are grouped together using the normalized $l^2$-distance as dissimilarity measure:

$$d(B_R, B_i) = \frac{\|B_R - B_i\|_2^2}{N_1^2}$$

with group $B_G$ formed by selecting blocks that have distance below the threshold $\tau$:

$$B_G = \{ B_i : d(B_R, B_i) \leq \tau \}$$

The Collaborative Filtering\footnote{Interestingly, collaborative filtering has been the backbone of recommendation systems such as by Netflix and Spotify \cite{bellLessonsNetflixPrize2007,drorYahooMusicDataset2012}.}\todo[disable]{Reference for the Netfilx/Spotify statement?} shown in \cref{alg:collaborativefiltering} is then applied to the grouped blocks. This step consists of a 3D transform such as the discrete cosine transform (or the wavelet transform can be used).
\todo[inline]{This 3D stacking and 3D filtering is a crucial component, which should be elaborated / illustrated more.}
A filter is applied to the transformed blocks to remove noise, initially by hard thresholding and in the second run by Wiener filtering. The inverse 3D transform is then applied to the filtered blocks, and the filtered blocks are aggregated to form the estimate. The first run is considered the basic estimate, and it is only after Collaborative Wiener filtering that the final estimate is obtained.
\todo[inline]{One a coarse level, this is all correct, but I would put much more detail. Also a sketch would be helpful.}
    
% Collaborative Filtering Algorithm
\begin{algorithm}
    \caption{Collaborative Filtering}\label{alg:collaborativefiltering}
    \begin{algorithmic}[1]
    \Require Group of similar blocks $B_{G}$, noise variance $\sigma^2$
    \Ensure Filtered block $B_{F}$
    \Procedure{CollaborativeFiltering}{$B_{G}$, $\sigma^2$}
        \State $B_{T} \gets \textsc{3DTransform}(B_{G})$
        \State $B_{F} \gets \textsc{ApplyFiltering}(B_{T}, \sigma^2)$
        \State $B_{I} \gets \textsc{Inverse3DTransform}(B_{F})$
        \State Aggregate $B_{I}$ into $B_{F}$
        \State \textbf{return} $B_{F}$
    \EndProcedure
    \end{algorithmic}
\end{algorithm}

The \gls{BM3D} algorithm had showed one of the best denoising performances and can only be contested by the recent deep-learning based denoising methods. 

\section{Poisson Noise Model}\label{sec:poisson-noise-model}
In imaging systems, the observed intensity $x$ at voxel $\mathbf{i}$ is a stochastic mapping of the latent distribution $y$ due to the inherent noise in the system. In low light settings, such as photon-limited imaging, the voxel-wise observations can be modeled as independent Poisson \glspl{rv}\todo[inline]{Took me a bit to figure out that r.v.s is an automatically inserted abbreviation. I would only abbreviate longs terms that are used regularly. The random variable is not so bad that it needs to be abbreviated.}\tododone[inline]{Actually r.v. is used quite frequently in the text, starting from the introduction so I thought it useful.} with parameter $y_{\mathbf{i}}$--the true intensity \cite{makitaloOptimalInversionAnscombe2011,kimDeepLearningbasedStatistical2021}. This is shown in \cref{section:photoelectron-counting-stats} to be true for a constant intensity light source.

The voxel-wise intensity can be expressed as $x_{\mathbf{i}} \sim \text{Poi}(y_{\mathbf{i}})$, where $\text{Poi}(y_{\mathbf{i}})$ denotes the Poisson distribution with parameter $y_{\mathbf{i}}$. The \gls{PMF} of the observed value $x_{\mathbf{i}}$ conditioned on the true intensity $y_{\mathbf{i}}$ is given by:

\begin{equation}
    P(x_{\mathbf{i}} = x| y_{\mathbf{i}} = y) = \frac{y^x e^{-y}}{x!}
\end{equation}

Here, $x$ represents the observation at voxel $X$\todo[inline]{What is this voxel $X$? Do you mean $\mathbf{i}$? In any case, some more explanations would be helpful.}, while $y$ corresponds to the underlying intensity that we aim to recover. Formally $\mathbb{E}[x_{\mathbf{i}} | y_{\mathbf{i}}] = y_{\mathbf{i}}$\todo[inline]{How can you conclude that and what does this mean exatly? Did you introduce the stochastic terminology already?}

The Poisson noise can then be written as:\todo[inline]{Why do we need the expectation to the noise?}
\begin{equation}
    N_{\mathbf{i}} = x_{\mathbf{i}} - \mathbb{E}[x_{\mathbf{i}} | y_{\mathbf{i}}]
\end{equation}

This noise is signal dependent as the variance is dependent on the true signal $\text{Var}[N_{\mathbf{i}} | y_{\mathbf{i}}] = [x_{\mathbf{i}} | y_{\mathbf{i}}] = y_{\mathbf{i}}$ and hence it can be seen that the with decreasing intensity, the noise increases.

\section{Variance Stabilization Transform: Anscombe}

\Glspl{VST} \todo[inline]{Is the acronym VST already defined? Those are usually spelled out at first use, not only in once in some acronym table.}\tododone[inline]{Yes it happens automatically. It's defined in the introduction of the chapter. If preferred, I can redefine here.} are used to map the values of the data \todo[inline]{It would be helpful to state that one starts here with data samples from a distribution where the variance depends on the signal (pointing to the previous section as an example).} to a new domain so that the variance becomes constant. \citeauthor{anscombeTransformationPoissonBinomial1948} \cite{anscombeTransformationPoissonBinomial1948} introduced such a \gls{VST} for data distributed according to the Poisson, Binomial, and Negative Binomial distributions. The Anscombe transform for the Poisson distribution is defined as:\todo[inline]{Stat from where to here $T$ maps, I guess it is meant to map non-negative numbers to non-negative numbers, e.g., $T:[0,\infty)\to[0,\infty),X\mapsto...$.}\todo[inline]{Is this supposed to use an array notation? In the sense that $X$ is a 2D-array? If so, I would first state what it does with a single intensity value.}
\begin{equation}
    T(X) = 2 \sqrt{X + \frac{3}{8}}
\end{equation}

Applying this transformation to a Poisson distributed \gls{rv} maps the data such that the variance becomes approximately constant\todo[inline]{In which sense approximately? I'd say that a plot of the variance before and after stabilization would be very illustrative here.}. $T(X)$ can then be denoised using \gls{AWGN} denoising techniques such as \gls{BM3D}. 
The denoised signal $\hat{Y}_{\text{bm3d}}$ \todo[disable]{Bad notation. $\mathbb{Z}$ is usually the set of integers.} is an estimate of expected value of $T(X)$ conditioned on the true signal $Y$ we aim to recover.\todo[inline]{I don't understand this part and what you do with the expectation here. Why is this more than just ``apply $T$, denoise, apply $T^{-1}$''?}
\begin{equation}
    \mathbb{X} = \mathbb{E}[T(X) | Y]
\end{equation}
Hence, the final estimate for the true signal $Y$ can be obtained by applying the inverse Anscombe transform to $\mathbb{X}$.
\begin{equation}
    \hat{Y} = T^{-1}(\mathbb{X}) = \mathbb{E}[X | T(X) = \mathbb{X}]
\end{equation}
Since the transformation is non-linear, an algebraic inverse is asymptotically biased. \citeauthor{makitaloOptimalInversionAnscombe2011} \cite{makitaloOptimalInversionAnscombe2011} proposed an exact unbiased inverse of $\hat{Y}_{\text{bm3d}}$ giving the denoised estimate $\hat{Y}$. This method performs better than methods based on explicit Poisson noise removal. Therefore, in the next few sections we make use of the scheme described in \cref{alg:anscombe-bm3d} to denoise 2D image slices from the \gls{MPES} data.

\begin{algorithm}
    \caption{Algorithm to Denoise Poisson Corrupted Images}\label{alg:anscombe-bm3d}
    \begin{algorithmic}[1]
    \Require Noisy image $X$
    \Ensure Denoised image $\hat{Y}$
    \Statex
    \Procedure{AnscombeBM3D}{$X$, $\sigma^2$}
        \State $\hat{Y}_{\text{T}} \gets T(X)$
        
        \State $\hat{Y}_{\text{bm3d}} \gets \textsc{BM3D}(\hat{Y}_{\text{T}}, \sigma^2)$
        
        \State $\hat{Y} \gets T^{-1}(\hat{Y}_{\text{bm3d}})$
        
        \State \textbf{return} $\hat{Y}$
    \EndProcedure
    \end{algorithmic}
\end{algorithm}


